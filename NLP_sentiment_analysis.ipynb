{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4e772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the Excel file\n",
    "df = pd.read_csv(\"chatgpt_style_reviews.csv\")\n",
    "\n",
    "print(\"First 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcd240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nDataset info:\")\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMissing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96013f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nRating distribution:\")\n",
    "print(df['rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e33563c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d38f36cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa400d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d6c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower() # Lowercase\n",
    "    text = re.sub(r'[^a-z\\s]', '', text) # Remove special chars/numbers\n",
    "    words = text.split() \n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words] # Tokenize and lemmatize\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66faa63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned_review'] = df['review'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a084803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9a32f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add review length\n",
    "df['review_length'] = df['review'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c15c5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert date to datetime\n",
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a72aacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66b8034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#Rating Distribution (Bar Chart)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='rating', data=df, palette='viridis')\n",
    "plt.title('Distribution of Review Ratings (1-5 Stars)')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d20531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helpful Reviews (Pie Chart)\n",
    "helpful_threshold = 10\n",
    "helpful = df[df['helpful_votes'] >= helpful_threshold]\n",
    "not_helpful = df[df['helpful_votes'] < helpful_threshold]\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie([len(helpful), len(not_helpful)], \n",
    "        labels=[f'Helpful (≥{helpful_threshold} votes)', 'Not Helpful'], \n",
    "        autopct='%1.1f%%', colors=['#66b3ff', '#ff9999'])\n",
    "plt.title('Proportion of Helpful Reviews')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf3cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keywords in Positive vs Negative Reviews (Word Clouds)\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "# Positive reviews (4-5 stars)\n",
    "positive_text = ' '.join(df[df['rating'] >= 4]['cleaned_review'])\n",
    "wordcloud_pos = WordCloud(width=800, height=400, background_color='white').generate(positive_text)\n",
    "\n",
    "# Negative reviews (1-2 stars)\n",
    "negative_text = ' '.join(df[df['rating'] <= 2]['cleaned_review'])\n",
    "wordcloud_neg = WordCloud(width=800, height=400, background_color='black').generate(negative_text)\n",
    "\n",
    "# Plot\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1.imshow(wordcloud_pos, interpolation='bilinear')\n",
    "ax1.set_title('Positive Reviews (4-5 Stars)')\n",
    "ax1.axis('off')\n",
    "ax2.imshow(wordcloud_neg, interpolation='bilinear')\n",
    "ax2.set_title('Negative Reviews (1-2 Stars)')\n",
    "ax2.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91088d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average Rating Over Time (Line Chart)\n",
    "df['month'] = df['date'].dt.to_period('M')\n",
    "monthly_avg = df.groupby('month')['rating'].mean()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "monthly_avg.plot(marker='o', color='purple')\n",
    "plt.title('Average Rating Trend Over Time')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af943b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ratings by Location (Bar Chart)\n",
    "top_locations = df['location'].value_counts().head(10).index\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='location', y='rating', data=df[df['location'].isin(top_locations)], palette='Set3')\n",
    "plt.title('Rating Distribution by Top 10 Locations')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1684ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Platform Comparison (Web vs Mobile)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='platform', y='rating', data=df, palette='pastel')\n",
    "plt.title('Rating Distribution by Platform')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b7efd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Verified vs Non-Verified Users\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x='verified_purchase', hue='rating', data=df, palette='coolwarm')\n",
    "plt.title('Rating Distribution: Verified vs Non-Verified Users')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c373a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sentiment mapping\n",
    "def get_sentiment(rating):\n",
    "    if rating >= 4:\n",
    "        return 'positive'\n",
    "    elif rating == 3:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'negative'\n",
    "\n",
    "# Create the column\n",
    "df['sentiment'] = df['rating'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b640302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Review Length vs Sentiment (Boxplot)\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='sentiment', y='review_length', data=df, palette='autumn', \n",
    "            order=['negative', 'neutral', 'positive'])\n",
    "plt.yscale('log')\n",
    "plt.title('Review Length by Sentiment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1690a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top Words in 1-Star Reviews\n",
    "from collections import Counter\n",
    "\n",
    "one_star_words = ' '.join(df[df['rating'] == 1]['cleaned_review']).split()\n",
    "word_freq = Counter(one_star_words).most_common(20)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=[word[0] for word in word_freq], y=[word[1] for word in word_freq], palette='Reds_r')\n",
    "plt.title('Top 20 Words in 1-Star Reviews')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b03bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best-Rated ChatGPT Version\n",
    "plt.figure(figsize=(12, 6))\n",
    "df.groupby('version')['rating'].mean().sort_values().plot(kind='barh', color='teal')\n",
    "plt.title('Average Rating by ChatGPT Version')\n",
    "plt.xlabel('Average Rating')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd85d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Training & Evaluation\n",
    "#Feature Engineering\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "tfidf = TfidfVectorizer(max_features=5000, ngram_range=(1, 2))\n",
    "X = tfidf.fit_transform(df['cleaned_review'])\n",
    "y = df['sentiment']  # Created during EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e875bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train-Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150edf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Models \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Naive Bayes\": MultinomialNB(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "    # Track the best model\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119518bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate Metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate predictions with the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Classification report\n",
    "print(\"Best Model Evaluation:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    confusion_matrix(y_test, y_pred), \n",
    "    annot=True, \n",
    "    fmt='d', \n",
    "    cmap='Blues',\n",
    "    xticklabels=['Negative', 'Neutral', 'Positive'],\n",
    "    yticklabels=['Negative', 'Neutral', 'Positive']\n",
    ")\n",
    "plt.title(\"Confusion Matrix (Best Model)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c2d1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "from google_play_scraper import Sort, reviews_all\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151e91d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory if it doesn't exist\n",
    "os.makedirs('data', exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64c8857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google_play_scraper import reviews_all, Sort\n",
    "\n",
    "reviews = reviews_all(\n",
    "    'com.openai.chatgpt',\n",
    "    lang='en',\n",
    "    country='us',\n",
    "    sort=Sort.NEWEST,\n",
    "    count=1000  # Number of reviews\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(reviews)[['content', 'score', 'at']]\n",
    "df.columns = ['review', 'rating', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8073c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61df5eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check basic stats\n",
    "print(df.info())\n",
    "print(df['rating'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f3b1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('chatgpt_play_store_reviews.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25ba6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "scraped_data = df.dropna(subset=['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9843720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()  # Lowercase\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    return text\n",
    "\n",
    "scraped_data['cleaned_review'] = scraped_data['review'].apply(clean_text)\n",
    "scraped_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671e960",
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_df = pd.read_csv(\"chatgpt_style_reviews.csv\") \n",
    "scraped_df = pd.read_csv(\"chatgpt_play_store_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440cfe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_df = scraped_df.rename(columns={'content': 'review'})\n",
    "scraped_df['platform'] = 'Mobile'  # Add missing column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8d0613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge vertically\n",
    "combined_df = pd.concat([existing_df, scraped_df], ignore_index=True)\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae3d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38593bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def is_english_simple(text):\n",
    "    text = str(text).lower()\n",
    "    # Basic check: >70% typical English characters/words\n",
    "    english_chars = len(re.findall(r'[a-z\\\\s]', text))\n",
    "    return english_chars / len(text) > 0.7 if text else False\n",
    "\n",
    "combined_df = combined_df[combined_df['review'].apply(is_english_simple)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd837ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43239fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cad91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all columns you want to KEEP\n",
    "columns_to_keep = ['review', 'rating', 'date', 'platform']  \n",
    "\n",
    "# Drop all other columns (in-place)\n",
    "combined_df.drop(columns=combined_df.columns.difference(columns_to_keep), inplace=True)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40efb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('final_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a80136",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load preprocessed English data\n",
    "df = pd.read_csv('final_data.csv')\n",
    "\n",
    "# Create sentiment labels (if not already done)\n",
    "df['sentiment'] = df['rating'].apply(\n",
    "    lambda x: 'positive' if x >=4 else 'negative' if x <=2 else 'neutral'\n",
    ")\n",
    "\n",
    "# Verify class distribution\n",
    "print(df['sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f19dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Option A: TF-IDF (Best for traditional ML)\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=5000,\n",
    "    ngram_range=(1, 2),  # Capture phrases like \"not good\"\n",
    "    stop_words='english'\n",
    ")\n",
    "X = tfidf.fit_transform(df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f39f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, \n",
    "    df['sentiment'],\n",
    "    test_size=0.2,\n",
    "    stratify=df['sentiment'],  # Preserve class balance\n",
    "    random_state=43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dcbf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Naive Bayes\": MultinomialNB()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    print(f\"{name} Accuracy: {model.score(X_test, y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e101f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# For best traditional model\n",
    "best_model = LogisticRegression(max_iter=1000).fit(X_train, y_train)\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), \n",
    "            annot=True, fmt='d',\n",
    "            xticklabels=best_model.classes_,\n",
    "            yticklabels=best_model.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bab3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "# Save both TF-IDF and model\n",
    "with open('sentiment_pipeline.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'tfidf': tfidf,\n",
    "        'model': best_model\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470bf390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from textblob import TextBlob\n",
    "\n",
    "def load_model():\n",
    "    \"\"\"Load the sentiment analysis pipeline\"\"\"\n",
    "    try:\n",
    "        with open('sentiment_pipeline.pkl', 'rb') as f:\n",
    "            pipeline = pickle.load(f)\n",
    "        return pipeline['model'], pipeline['tfidf']\n",
    "    except FileNotFoundError:\n",
    "        print(\"Model file not found. Using TextBlob as fallback.\")\n",
    "        return None, None\n",
    "\n",
    "def predict_sentiment(text, model=None, vectorizer=None):\n",
    "    \"\"\"Predict sentiment with confidence score\"\"\"\n",
    "    if model and vectorizer:\n",
    "        vec = vectorizer.transform([text])\n",
    "        proba = model.predict_proba(vec)[0]\n",
    "        sentiment = model.predict(vec)[0]\n",
    "        confidence = round(max(proba) * 100, 1)\n",
    "    else:\n",
    "        analysis = TextBlob(text)\n",
    "        sentiment = 'positive' if analysis.sentiment.polarity > 0 else 'negative'\n",
    "        confidence = round(abs(analysis.sentiment.polarity) * 100, 1)\n",
    "    return sentiment, confidence\n",
    "\n",
    "def main():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"💬 CHATGPT REVIEW SENTIMENT ANALYZER\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"Type a ChatGPT review and press Enter to analyze\")\n",
    "    print(\"Type 'quit' to exit\\n\")\n",
    "    \n",
    "    model, vectorizer = load_model()\n",
    "    \n",
    "    while True:\n",
    "        review = input(\"\\nEnter a ChatGPT review (or 'quit' to exit): \").strip()\n",
    "        \n",
    "        # Exit condition\n",
    "        if review.lower() == 'quit':\n",
    "            print(\"\\nThank you for using the analyzer! Goodbye! 👋\")\n",
    "            break  # This exits the loop\n",
    "        \n",
    "        if not review:\n",
    "            print(\"⚠️ Please enter a valid review\")\n",
    "            continue\n",
    "            \n",
    "        sentiment, confidence = predict_sentiment(review, model, vectorizer)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"📝 REVIEW: {review}\")\n",
    "        print(\"-\"*50)\n",
    "        print(f\"🧠 SENTIMENT: {'👍 POSITIVE' if sentiment == 'positive' else '👎 NEGATIVE' if sentiment == 'negative' else '😐 NEUTRAL'}\")\n",
    "        print(f\"🎯 CONFIDENCE: {confidence}%\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  # Program will exit completely after loop breaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06649689",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
